{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a41c79",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup Constant Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import timm\n",
    "import argparse\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =========================\n",
    "# Constant Configuration\n",
    "# =========================\n",
    "HERBARIUM_DOMAIN = 0  # from data_utils: 0 = herbarium, 1 = photo\n",
    "PHOTO_DOMAIN = 1\n",
    "EMBED_DIM = 512  # or whatever you chose earlier\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LR_HEAD = 1e-6          # Head needs to learn fast\n",
    "LR_BACKBONE_MAX = 1e-6  # Topmost backbone layers\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LAYER_DECAY = 0.8       # Each layer gets 80% of the LR of the layer above it\n",
    "\n",
    "LR_BACKBONE = 1e-6   # smaller LR for pretrained DINO\n",
    "LR_HEAD = 1e-6       # larger LR for randomly init projection head\n",
    "WEIGHT_DECAY = 1e-4\n",
    "# =========================\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "COMMON_DIR = PROJECT_ROOT / \"common\"\n",
    "\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / \"experiments\" / \"triplet_dann\" / \"checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if str(COMMON_DIR) not in sys.path:\n",
    "    sys.path.append(str(COMMON_DIR))\n",
    "\n",
    "from config import DATA_ROOT\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import build_train_dataset, build_test_dataset, get_with_without_label_sets\n",
    "\n",
    "train_ds = build_train_dataset()\n",
    "test_ds = build_test_dataset()\n",
    "with_set, without_set = get_with_without_label_sets()\n",
    "\n",
    "len(train_ds), len(test_ds), len(with_set), len(without_set), DATA_ROOT\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78765050",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = train_ds[10]\n",
    "img = sample[\"image\"]\n",
    "label = sample[\"label\"]\n",
    "domain = sample[\"domain\"]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0).numpy() * 0.229 + 0.485)  # quick un-normalise-ish\n",
    "plt.title(f\"label={label}, domain={domain}\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset loading and with/without-pairs metadata\n",
    "# If your common/ is a package, this should work directly.\n",
    "# Otherwise, you may need to adjust sys.path above this cell.\n",
    "from config import (\n",
    "    PROJECT_ROOT,\n",
    "    NUM_CLASSES,\n",
    ")\n",
    "from data_utils import (\n",
    "    build_train_dataset,\n",
    "    build_test_dataset,\n",
    "    get_with_without_label_sets,\n",
    ")\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Build datasets\n",
    "train_dataset = build_train_dataset()\n",
    "test_dataset = build_test_dataset()\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# with/without-pair LABEL SETS (already mapped to [0..NUM_CLASSES-1])\n",
    "with_set, without_set = get_with_without_label_sets()\n",
    "print(f\"Classes with pairs    : {len(with_set)}\")\n",
    "print(f\"Classes without pairs : {len(without_set)}\")\n",
    "\n",
    "# Quick sanity check: all labels in data should be within [0..NUM_CLASSES-1]\n",
    "all_train_labels = {s[\"label\"] for s in train_dataset.samples}\n",
    "all_test_labels = {s[\"label\"] for s in test_dataset.samples}\n",
    "\n",
    "print(\"Distinct train labels:\", len(all_train_labels))\n",
    "print(\"Distinct test labels :\", len(all_test_labels))\n",
    "\n",
    "missing_from_sets = all_train_labels.union(all_test_labels) - (with_set | without_set)\n",
    "if missing_from_sets:\n",
    "    print(\"[Warning] Some labels not in with/without sets:\", sorted(missing_from_sets))\n",
    "else:\n",
    "    print(\"All labels covered by with/without splits.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf19850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: TripletDataset for cross-domain metric learning\n",
    "class TripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Samples cross-domain triplets:\n",
    "      - anchor: herbarium OR photo\n",
    "      - positive: same class, other domain\n",
    "      - negative: different class (any domain)\n",
    "    Using only with-pair species (labels in with_set).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_dataset, with_labels):\n",
    "        \"\"\"\n",
    "        base_dataset: HerbFieldDataset (train)\n",
    "        with_labels : iterable of label indices that have herbarium-photo pairs\n",
    "        \"\"\"\n",
    "        self.base_dataset = base_dataset\n",
    "        self.with_labels = sorted(set(with_labels))\n",
    "\n",
    "        # Pre-build index: label -> {0: [idxs of herbarium], 1: [idxs of photo]}\n",
    "        self.label_domain_index = {}\n",
    "        for idx, s in enumerate(self.base_dataset.samples):\n",
    "            lbl = s[\"label\"]\n",
    "            dom = s[\"domain\"]\n",
    "            if lbl not in self.with_labels:\n",
    "                continue\n",
    "            if lbl not in self.label_domain_index:\n",
    "                self.label_domain_index[lbl] = {\n",
    "                    HERBARIUM_DOMAIN: [],\n",
    "                    PHOTO_DOMAIN: [],\n",
    "                }\n",
    "            self.label_domain_index[lbl][dom].append(idx)\n",
    "\n",
    "        # Filter out labels that don't actually have both domains\n",
    "        # (in case the list file is weird)\n",
    "        cleaned_labels = []\n",
    "        for lbl in self.with_labels:\n",
    "            doms = self.label_domain_index.get(lbl, None)\n",
    "            if doms is None:\n",
    "                continue\n",
    "            if len(doms[HERBARIUM_DOMAIN]) > 0 and len(doms[PHOTO_DOMAIN]) > 0:\n",
    "                cleaned_labels.append(lbl)\n",
    "\n",
    "        self.with_labels = cleaned_labels\n",
    "        print(f\"[TripletDataset] Usable with-pair classes: {len(self.with_labels)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Arbitrary: we just want many triplets per epoch; using base length is fine.\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def _sample_cross_pair(self):\n",
    "        # Choose a class that has both domains\n",
    "        lbl = random.choice(self.with_labels)\n",
    "        # Randomly pick which domain is anchor vs positive\n",
    "        dom_anchor = random.choice([HERBARIUM_DOMAIN, PHOTO_DOMAIN])\n",
    "        dom_pos = PHOTO_DOMAIN if dom_anchor == HERBARIUM_DOMAIN else HERBARIUM_DOMAIN\n",
    "\n",
    "        anchor_idx = random.choice(self.label_domain_index[lbl][dom_anchor])\n",
    "        pos_idx = random.choice(self.label_domain_index[lbl][dom_pos])\n",
    "\n",
    "        # Negative: any *other* class from with_labels, any domain that has examples\n",
    "        neg_lbl = random.choice([c for c in self.with_labels if c != lbl])\n",
    "        neg_dom_choices = []\n",
    "        for dom in (HERBARIUM_DOMAIN, PHOTO_DOMAIN):\n",
    "            if self.label_domain_index[neg_lbl][dom]:\n",
    "                neg_dom_choices.append(dom)\n",
    "        neg_dom = random.choice(neg_dom_choices)\n",
    "        neg_idx = random.choice(self.label_domain_index[neg_lbl][neg_dom])\n",
    "\n",
    "        return anchor_idx, pos_idx, neg_idx, lbl, neg_lbl\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx is ignored; we generate a fresh triplet every time\n",
    "        anchor_idx, pos_idx, neg_idx, lbl, neg_lbl = self._sample_cross_pair()\n",
    "\n",
    "        a = self.base_dataset[anchor_idx]\n",
    "        p = self.base_dataset[pos_idx]\n",
    "        n = self.base_dataset[neg_idx]\n",
    "\n",
    "        return {\n",
    "            \"anchor\": a[\"image\"],\n",
    "            \"positive\": p[\"image\"],\n",
    "            \"negative\": n[\"image\"],\n",
    "            \"anchor_label\": a[\"label\"],\n",
    "            \"positive_label\": p[\"label\"],\n",
    "            \"negative_label\": n[\"label\"],\n",
    "            \"anchor_domain\": a[\"domain\"],\n",
    "            \"positive_domain\": p[\"domain\"],\n",
    "            \"negative_domain\": n[\"domain\"],\n",
    "        }\n",
    "\n",
    "# Instantiate TripletDataset + DataLoader\n",
    "\n",
    "triplet_dataset = TripletDataset(train_dataset, with_set)\n",
    "triplet_loader = DataLoader(\n",
    "    triplet_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "batch = next(iter(triplet_loader))\n",
    "print(\"Triplet batch keys:\", batch.keys())\n",
    "print(\"Triplet batch anchor tensor shape:\", batch[\"anchor\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917541b9",
   "metadata": {},
   "source": [
    "# Architecture Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 – Model definition (DINOv2 backbone)\n",
    "class TripletEncoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        backbone_type: str = \"dinov2_vitb14\",\n",
    "        pretrained: bool = True,\n",
    "        freeze_backbone: bool = False,\n",
    "        proj_hidden_dim: int = 1024,\n",
    "        proj_layers: int = 2,\n",
    "        dropout_p: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone_type = backbone_type.lower()\n",
    "\n",
    "        # Load pretrained backbone weights from external checkpoint\n",
    "        torch.serialization.add_safe_globals([argparse.Namespace])\n",
    "        ckpt = torch.load(\n",
    "            PROJECT_ROOT / \"model_best.pth.tar\",\n",
    "            map_location=\"cpu\",\n",
    "            weights_only=False\n",
    "        )\n",
    "\n",
    "        state = ckpt[\"state_dict\"]\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
    "            pretrained=False,\n",
    "            num_classes=0  # remove original classifier\n",
    "        )\n",
    "\n",
    "        missing, unexpected = backbone.load_state_dict(state, strict=False)\n",
    "        print(\"Missing keys:\", missing)\n",
    "        print(\"Unexpected keys:\", unexpected)\n",
    "\n",
    "        # Use checkpoint-initialised backbone instead of hub-loaded one\n",
    "        # self.backbone = torch.hub.load(\"facebookresearch/dinov2\", self.backbone_type)\n",
    "        self.backbone = backbone\n",
    "\n",
    "        # ViT backbone exposes embedding dimension like this:\n",
    "        feat_dim = getattr(self.backbone, \"num_features\", None)\n",
    "        if feat_dim is None:\n",
    "            feat_dim = getattr(self.backbone, \"embed_dim\", None)\n",
    "        if feat_dim is None:\n",
    "            raise RuntimeError(\n",
    "                f\"Backbone {self.backbone_type} has no 'embed_dim'/'num_features' attribute; \"\n",
    "                \"inspect the model to get the feature dimension.\"\n",
    "            )\n",
    "\n",
    "        # ---- optional freezing of entire backbone ----\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # ---- projection head (feat_dim -> embed_dim) ----\n",
    "        proj_layers_list = []\n",
    "        in_dim = feat_dim\n",
    "        for i in range(proj_layers - 1):\n",
    "            proj_layers_list.append(nn.Linear(in_dim, proj_hidden_dim))\n",
    "            proj_layers_list.append(nn.BatchNorm1d(proj_hidden_dim))\n",
    "            proj_layers_list.append(nn.ReLU(inplace=True))\n",
    "            if dropout_p > 0:\n",
    "                proj_layers_list.append(nn.Dropout(dropout_p))\n",
    "            in_dim = proj_hidden_dim\n",
    "        proj_layers_list.append(nn.Linear(in_dim, embed_dim))\n",
    "\n",
    "        self.proj_head = nn.Sequential(*proj_layers_list)\n",
    "\n",
    "    # ---------- NEW: fine-tuning control ----------\n",
    "    def set_backbone_trainable(self, mode: str = \"all\", last_k: int = 2):\n",
    "        \"\"\"\n",
    "        Control which backbone layers are trainable.\n",
    "\n",
    "        mode:\n",
    "          - \"all\"  : fine-tune entire backbone\n",
    "          - \"none\" : freeze entire backbone (only projection head trains)\n",
    "          - \"last_k\": unfreeze only last `last_k` transformer blocks (DINOv2 only)\n",
    "\n",
    "        For ResNet, \"last_k\" is not implemented (only all/none).\n",
    "        \"\"\"\n",
    "        mode = mode.lower()\n",
    "        if mode not in (\"all\", \"none\", \"last_k\"):\n",
    "            raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "        # First freeze everything\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        if mode == \"none\":\n",
    "            return  # all frozen, only proj_head will train\n",
    "\n",
    "        if mode == \"all\":\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = True\n",
    "            return\n",
    "\n",
    "        # mode == \"last_k\"\n",
    "        if self.backbone_type.startswith(\"dinov2\"):\n",
    "            blocks = getattr(self.backbone, \"blocks\", None)\n",
    "            if blocks is None:\n",
    "                raise RuntimeError(\n",
    "                    \"DINOv2 backbone has no .blocks attribute; inspect the model to adapt this.\"\n",
    "                )\n",
    "            last_k = min(last_k, len(blocks))\n",
    "            for blk in blocks[-last_k:]:\n",
    "                for p in blk.parameters():\n",
    "                    p.requires_grad = True\n",
    "        else:\n",
    "            raise NotImplementedError(\"mode='last_k' only implemented for DINOv2 in this notebook.\")\n",
    "\n",
    "    def forward_backbone(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns backbone features (before projection).\n",
    "        DINOv2 ViT: global features (B, embed_dim)\n",
    "        \"\"\"\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        feats = self.forward_backbone(x)\n",
    "        z = self.proj_head(feats)\n",
    "        z = F.normalize(z, p=2, dim=-1)\n",
    "        return z\n",
    "\n",
    "# Instantiate with DINOv2 backbone\n",
    "model = TripletEncoder(\n",
    "    embed_dim=EMBED_DIM,\n",
    "    backbone_type=\"dinov2_vitb14\",\n",
    "    pretrained=True,\n",
    "    freeze_backbone=False,  # we'll control fine-tuning explicitly below\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "print(\"Backbone:\", model.backbone_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a323e",
   "metadata": {},
   "source": [
    "## Fine-tuning selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 1. Unfreeze the last 9 blocks\n",
    "model.set_backbone_trainable(mode=\"last_k\", last_k=5)\n",
    "\n",
    "# 2. Build parameter groups with decay\n",
    "param_groups = []\n",
    "\n",
    "# Group A: The Projection Head (Highest LR)\n",
    "param_groups.append({\n",
    "    \"params\": [p for p in model.proj_head.parameters() if p.requires_grad],\n",
    "    \"lr\": LR_HEAD,\n",
    "    \"weight_decay\": WEIGHT_DECAY\n",
    "})\n",
    "\n",
    "# Group B: The Backbone Blocks (Decaying LR)\n",
    "# We iterate blocks in reverse: Block 11 -> Block 0\n",
    "current_lr = LR_BACKBONE_MAX\n",
    "\n",
    "if hasattr(model.backbone, \"blocks\"):\n",
    "    # Iterate only over blocks that have gradients (the last k)\n",
    "    for block in reversed(model.backbone.blocks):\n",
    "        # Only add if this block was unfrozen\n",
    "        block_params = [p for p in block.parameters() if p.requires_grad]\n",
    "        if block_params:\n",
    "            print(f\"Block LR: {current_lr:.2e}\") # Debug print\n",
    "            param_groups.append({\n",
    "                \"params\": block_params,\n",
    "                \"lr\": current_lr,\n",
    "                \"weight_decay\": WEIGHT_DECAY\n",
    "            })\n",
    "            current_lr *= LAYER_DECAY  # Decay for the next block down\n",
    "            \n",
    "backbone_params = [p for p in model.backbone.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.proj_head.parameters() if p.requires_grad]\n",
    "\n",
    "print(f\"Trainable backbone params: {sum(p.numel() for p in backbone_params):,}\")\n",
    "print(f\"Trainable head params    : {sum(p.numel() for p in head_params):,}\")\n",
    "\n",
    "# 3. Create Optimizer\n",
    "optimizer = optim.AdamW(param_groups)\n",
    "# optional LR scheduler, same for both groups\n",
    "EPOCHS = 30\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 – Optimizer with separate LR for backbone vs projection head\n",
    "\n",
    "\n",
    "\n",
    "# choose fine-tuning mode here:\n",
    "#   \"all\"   -> full DINO fine-tuning\n",
    "#   \"none\"  -> freeze DINO, train only projection\n",
    "#   \"last_k\" with last_k blocks\n",
    "model.set_backbone_trainable(mode=\"last_k\", last_k=9)\n",
    "\n",
    "\n",
    "backbone_params = [p for p in model.backbone.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.proj_head.parameters() if p.requires_grad]\n",
    "\n",
    "print(f\"Trainable backbone params: {sum(p.numel() for p in backbone_params):,}\")\n",
    "print(f\"Trainable head params    : {sum(p.numel() for p in head_params):,}\")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": LR_BACKBONE},\n",
    "        {\"params\": head_params, \"lr\": LR_HEAD},\n",
    "    ],\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# optional LR scheduler, same for both groups\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acd904",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 (Modified): Resume Training from Checkpoint\n",
    "\n",
    "# --- Setup ---\n",
    "torch.manual_seed(42)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "margin = 0.2\n",
    "triplet_loss_fn = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "CKPT_DIR = PROJECT_ROOT / \"experiments\" / \"2_stream\" / \"checkpoints_k9\"\n",
    "CKPT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RESUME LOGIC\n",
    "# ---------------------------------------------------------\n",
    "RESUME_FROM = \"epoch_1.pt\"  # The filename you want to load\n",
    "resume_path = CKPT_DIR / RESUME_FROM\n",
    "\n",
    "START_EPOCH = 0\n",
    "best_without_acc = 0.0\n",
    "best_acc = 0.0\n",
    "history = []\n",
    "\n",
    "if resume_path.exists():\n",
    "    print(f\"--> Loading checkpoint: {resume_path}\")\n",
    "    state_dict = torch.load(resume_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Extract epoch number from filename (e.g., \"epoch_1.pt\" -> 1)\n",
    "    # This assumes the file format is exactly \"epoch_{int}.pt\"\n",
    "    try:\n",
    "        START_EPOCH = int(RESUME_FROM.split(\"_\")[1].split(\".\")[0])\n",
    "        print(f\"--> Resuming start from Epoch {START_EPOCH + 1} (Index {START_EPOCH})\")\n",
    "        \n",
    "        # Since optimizer state wasn't saved, we start optimizer fresh, \n",
    "        # but we must step the scheduler to match the current epoch.\n",
    "        for _ in range(START_EPOCH):\n",
    "            scheduler.step()\n",
    "            \n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Could not parse epoch from filename, starting from next step manually.\")\n",
    "        START_EPOCH = 1 # Manual override if parsing fails\n",
    "\n",
    "    # Optional: Load history if it exists to keep the best score variable correct\n",
    "    history_path = CKPT_DIR / \"history.json\"\n",
    "    if history_path.exists():\n",
    "        with open(history_path, \"r\") as f:\n",
    "            history = json.load(f)\n",
    "            # Find best previous accuracy to prevent overwriting best_model.pt with worse results\n",
    "            for record in history:\n",
    "                if record[\"unpaired_top1\"] > best_without_acc:\n",
    "                    best_without_acc = record[\"unpaired_top1\"]\n",
    "        print(f\"--> History loaded. Best previous Unpaired Top-1: {best_without_acc:.4%}\")\n",
    "else:\n",
    "    print(f\"Checkpoint {resume_path} not found. Starting from scratch.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# HELPER FUNCTIONS (Same as before)\n",
    "# ---------------------------------------------------------\n",
    "def build_prototypes(model, loader):\n",
    "    model.eval()\n",
    "    proto_sum = torch.zeros(NUM_CLASSES, EMBED_DIM, device=device)\n",
    "    proto_count = torch.zeros(NUM_CLASSES, dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            images = batch[\"image\"].to(device, non_blocking=True)\n",
    "            labels = batch[\"label\"].to(device, non_blocking=True)\n",
    "            domains = batch[\"domain\"].to(device, non_blocking=True)\n",
    "            \n",
    "            mask = (domains == 0) # Herbarium only\n",
    "            if mask.sum() == 0: continue\n",
    "\n",
    "            emb = model(images[mask])\n",
    "            lbls = labels[mask]\n",
    "            \n",
    "            for e, l in zip(emb, lbls):\n",
    "                proto_sum[l] += e\n",
    "                proto_count[l] += 1\n",
    "    \n",
    "    prototypes = torch.zeros_like(proto_sum)\n",
    "    for c in range(NUM_CLASSES):\n",
    "        if proto_count[c] > 0:\n",
    "            prototypes[c] = proto_sum[c] / proto_count[c].float()\n",
    "            prototypes[c] = F.normalize(prototypes[c], p=2, dim=-1)\n",
    "            \n",
    "    return prototypes, proto_count\n",
    "\n",
    "def run_eval(model, loader, prototypes, proto_count):\n",
    "    model.eval()\n",
    "    num_classes = prototypes.shape[0]\n",
    "    k = min(5, num_classes)\n",
    "    valid_proto_mask = proto_count > 0\n",
    "\n",
    "    # (Counters initialization omitted for brevity, same as previous cell)\n",
    "    # ... [Assume counters set to 0] ...\n",
    "    total_overall = 0; correct1_overall = 0; correct5_overall = 0\n",
    "    total_with = 0; correct1_with = 0; correct5_with = 0\n",
    "    total_without = 0; correct1_without = 0; correct5_without = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs = batch[\"image\"].to(device, non_blocking=True)\n",
    "            labels = batch[\"label\"].to(device, non_blocking=True)\n",
    "            \n",
    "            emb = model(imgs)\n",
    "            sims = emb @ prototypes.T\n",
    "            sims[:, ~valid_proto_mask] = -1e9\n",
    "            topk_vals, topk_idx = sims.topk(k=k, dim=1)\n",
    "            preds_top1 = topk_idx[:, 0]\n",
    "\n",
    "            labels_cpu = labels.cpu().tolist()\n",
    "            top1_cpu = preds_top1.cpu().tolist()\n",
    "            topk_cpu = topk_idx.cpu().tolist()\n",
    "\n",
    "            for lbl, p1, pk_list in zip(labels_cpu, top1_cpu, topk_cpu):\n",
    "                total_overall += 1\n",
    "                if p1 == lbl: correct1_overall += 1\n",
    "                if lbl in pk_list: correct5_overall += 1\n",
    "\n",
    "                if lbl in with_set:\n",
    "                    total_with += 1\n",
    "                    if p1 == lbl: correct1_with += 1\n",
    "                    if lbl in pk_list: correct5_with += 1\n",
    "                elif lbl in without_set:\n",
    "                    total_without += 1\n",
    "                    if p1 == lbl: correct1_without += 1\n",
    "                    if lbl in pk_list: correct5_without += 1\n",
    "\n",
    "    def safe_div(num, den): return float(num) / float(den) if den > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"overall_top1\": safe_div(correct1_overall, total_overall),\n",
    "        \"overall_top5\": safe_div(correct5_overall, total_overall),\n",
    "        \"paired_top1\":  safe_div(correct1_with,    total_with),\n",
    "        \"paired_top5\":  safe_div(correct5_with,    total_with),\n",
    "        \"unpaired_top1\": safe_div(correct1_without, total_without),\n",
    "        \"unpaired_top5\": safe_div(correct5_without, total_without),\n",
    "        \"counts\": {\"overall\": total_overall, \"paired\": total_with, \"unpaired\": total_without},\n",
    "    }\n",
    "\n",
    "# --- Loaders ---\n",
    "proto_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "eval_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Starting Training from Epoch {START_EPOCH + 1} to {EPOCHS}...\")\n",
    "\n",
    "# --- Main Loop Modified Range ---\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    # 1. Train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    pbar = tqdm(triplet_loader, desc=f\"Ep {epoch+1}/{EPOCHS}\", leave=False)\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        anc = batch[\"anchor\"].to(device)\n",
    "        pos = batch[\"positive\"].to(device)\n",
    "        neg = batch[\"negative\"].to(device)\n",
    "        \n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            ea = model(anc)\n",
    "            ep = model(pos)\n",
    "            en = model(neg)\n",
    "            loss = triplet_loss_fn(ea, ep, en)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        count += 1\n",
    "        pbar.set_postfix({\"loss\": f\"{running_loss/count:.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / count\n",
    "    \n",
    "    # 2. Build Prototypes\n",
    "    prototypes, proto_count = build_prototypes(model, proto_loader)\n",
    "    \n",
    "    # 3. Evaluate\n",
    "    eval_metrics = run_eval(model, eval_loader, prototypes, proto_count)\n",
    "    \n",
    "    # 4. Record History\n",
    "    record = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": float(epoch_loss),\n",
    "        \"overall_top1\":  eval_metrics[\"overall_top1\"],\n",
    "        \"overall_top5\":  eval_metrics[\"overall_top5\"],\n",
    "        \"paired_top1\":   eval_metrics[\"paired_top1\"],\n",
    "        \"paired_top5\":   eval_metrics[\"paired_top5\"],\n",
    "        \"unpaired_top1\": eval_metrics[\"unpaired_top1\"],\n",
    "        \"unpaired_top5\": eval_metrics[\"unpaired_top5\"],\n",
    "        \"counts\": eval_metrics[\"counts\"],\n",
    "    }\n",
    "    history.append(record)\n",
    "    \n",
    "    print(\n",
    "        f\"[Epoch {epoch+1}] \"\n",
    "        f\"Loss: {epoch_loss:.4f} | \"\n",
    "        f\"Ov T1: {eval_metrics['overall_top1']:.4%} | \"\n",
    "        f\"Ov T5: {eval_metrics['overall_top5']:.4%} | \"\n",
    "        f\"Paired T1: {eval_metrics['paired_top1']:.4%} | \"\n",
    "        f\"Paired T5: {eval_metrics['paired_top5']:.4%} | \"\n",
    "        f\"Unpaired T1: {eval_metrics['unpaired_top1']:.4%} | \"\n",
    "        f\"Unpaired T5: {eval_metrics['unpaired_top5']:.4%} \"\n",
    "    )\n",
    "    \n",
    "    # 5. Save checkpoint\n",
    "    torch.save(model.state_dict(), CKPT_DIR / f\"epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Track best model\n",
    "    current_without_acc = eval_metrics[\"unpaired_top1\"]\n",
    "    current_with_acc = eval_metrics[\"paired_top1\"]\n",
    "    \n",
    "    should_save_best = False\n",
    "    if current_without_acc > best_without_acc:\n",
    "        # Better unpaired accuracy\n",
    "        best_without_acc = current_without_acc\n",
    "        best_acc = current_with_acc\n",
    "        should_save_best = True\n",
    "        print(f\"--> New Best Model Saved! (Unpaired Top-1 = {best_without_acc:.4%})\")\n",
    "    elif current_without_acc == best_without_acc and current_with_acc > best_acc:\n",
    "        # Same unpaired accuracy but better paired accuracy\n",
    "        best_acc = current_with_acc\n",
    "        should_save_best = True\n",
    "        print(f\"--> New Best Model Saved! (Unpaired Top-1 = {best_without_acc:.4%}, Paired Top-1 = {best_acc:.4%})\")\n",
    "    \n",
    "    if should_save_best:\n",
    "        torch.save(model.state_dict(), CKPT_DIR / \"best_model.pt\")\n",
    "        \n",
    "    # Save History\n",
    "    with open(CKPT_DIR / \"history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61efd659",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Build herbarium prototypes for all classes\n",
    "\n",
    "\n",
    "proto_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Accumulate sum and counts per class\n",
    "proto_sum = torch.zeros(NUM_CLASSES, EMBED_DIM, device=device)\n",
    "proto_count = torch.zeros(NUM_CLASSES, dtype=torch.long, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(proto_loader, desc=\"Building prototypes\", leave=False)\n",
    "    for batch in pbar:\n",
    "        images = batch[\"image\"].to(device, non_blocking=True)\n",
    "        labels = batch[\"label\"].to(device, non_blocking=True)\n",
    "        domains = batch[\"domain\"].to(device, non_blocking=True)\n",
    "\n",
    "        # Only herbarium samples\n",
    "        mask = (domains == HERBARIUM_DOMAIN)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        imgs_h = images[mask]\n",
    "        lbls_h = labels[mask]\n",
    "\n",
    "        emb = model(imgs_h)  # already normalized\n",
    "        for e, lbl in zip(emb, lbls_h):\n",
    "            proto_sum[lbl] += e\n",
    "            proto_count[lbl] += 1\n",
    "\n",
    "# Compute mean and re-normalize per class\n",
    "prototypes = torch.zeros_like(proto_sum)\n",
    "for c in range(NUM_CLASSES):\n",
    "    if proto_count[c] > 0:\n",
    "        prototypes[c] = proto_sum[c] / proto_count[c].float()\n",
    "        prototypes[c] = F.normalize(prototypes[c], p=2, dim=-1)\n",
    "    else:\n",
    "        # no herbarium for this class; leave as zeros (we'll detect later)\n",
    "        pass\n",
    "\n",
    "missing_proto = (proto_count == 0).nonzero(as_tuple=True)[0].tolist()\n",
    "if missing_proto:\n",
    "    print(\"[Warning] Classes with no herbarium prototypes:\", missing_proto)\n",
    "else:\n",
    "    print(\"All classes have herbarium prototypes.\")\n",
    "\n",
    "# Optionally save prototypes to disk\n",
    "proto_path = CKPT_DIR / \"epoch_4.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"prototypes\": prototypes.cpu(),\n",
    "        \"proto_count\": proto_count.cpu(),\n",
    "        \"embed_dim\": EMBED_DIM,\n",
    "    },\n",
    "    proto_path,\n",
    ")\n",
    "print(\"Saved prototypes to:\", proto_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint for evaluation\n",
    "CKPT_DIR_TEST = PROJECT_ROOT / \"experiments\" / \"2_stream\" / \"checkpoints_k5\"\n",
    "checkpoint_path = CKPT_DIR_TEST / \"epoch_25.pt\"\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    print(f\"✓ Loaded checkpoint: {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"⚠ Warning: Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"  Using current model state in memory\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluation (Top-1 / Top-5, overall + with/without-pair)\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "prototypes = prototypes.to(device)\n",
    "# if some prototypes are zero vectors (no herbarium), we will ignore them by masking later\n",
    "proto_norms = prototypes.norm(dim=1)\n",
    "valid_proto_mask = (proto_norms > 0.0)\n",
    "\n",
    "def evaluate_topk(k=5):\n",
    "    total = 0\n",
    "    correct_top1 = 0\n",
    "    correct_topk = 0\n",
    "\n",
    "    total_with = 0\n",
    "    correct_top1_with = 0\n",
    "    correct_topk_with = 0\n",
    "\n",
    "    total_without = 0\n",
    "    correct_top1_without = 0\n",
    "    correct_topk_without = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(eval_loader, desc=\"Evaluating\", leave=False)\n",
    "        for batch in pbar:\n",
    "            imgs = batch[\"image\"].to(device, non_blocking=True)\n",
    "            labels = batch[\"label\"].to(device, non_blocking=True)\n",
    "\n",
    "            emb = model(imgs)  # [B, D], normalized\n",
    "\n",
    "            # cosine similarity: dot product since embeddings & prototypes are unit-normalized\n",
    "            sims = emb @ prototypes.T  # [B, NUM_CLASSES]\n",
    "\n",
    "            # If some classes have invalid prototypes, set their sim to -inf\n",
    "            sims[:, ~valid_proto_mask] = -1e9\n",
    "\n",
    "            topk_vals, topk_idx = sims.topk(k=k, dim=1)  # [B, k]\n",
    "\n",
    "            # Overall\n",
    "            total_batch = labels.size(0)\n",
    "            total += total_batch\n",
    "\n",
    "            # Top-1\n",
    "            pred_top1 = topk_idx[:, 0]\n",
    "            correct1 = (pred_top1 == labels).sum().item()\n",
    "            correct_top1 += correct1\n",
    "\n",
    "            # Top-k\n",
    "            correctk = (topk_idx == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            correct_topk += correctk\n",
    "\n",
    "            # Split by with/without-pair\n",
    "            labels_cpu = labels.cpu().tolist()\n",
    "            pred_top1_cpu = pred_top1.cpu().tolist()\n",
    "            topk_idx_cpu = topk_idx.cpu().tolist()\n",
    "\n",
    "            for lbl, p1, pk_list in zip(labels_cpu, pred_top1_cpu, topk_idx_cpu):\n",
    "                in_with = lbl in with_set\n",
    "                in_without = lbl in without_set\n",
    "\n",
    "                if in_with:\n",
    "                    total_with += 1\n",
    "                    if p1 == lbl:\n",
    "                        correct_top1_with += 1\n",
    "                    if lbl in pk_list:\n",
    "                        correct_topk_with += 1\n",
    "                elif in_without:\n",
    "                    total_without += 1\n",
    "                    if p1 == lbl:\n",
    "                        correct_top1_without += 1\n",
    "                    if lbl in pk_list:\n",
    "                        correct_topk_without += 1\n",
    "\n",
    "    results = {\n",
    "        \"overall\": {\n",
    "            \"total\": total,\n",
    "            \"top1_correct\": correct_top1,\n",
    "            \"topk_correct\": correct_topk,\n",
    "        },\n",
    "        \"with\": {\n",
    "            \"total\": total_with,\n",
    "            \"top1_correct\": correct_top1_with,\n",
    "            \"topk_correct\": correct_topk_with,\n",
    "        },\n",
    "        \"without\": {\n",
    "            \"total\": total_without,\n",
    "            \"top1_correct\": correct_top1_without,\n",
    "            \"topk_correct\": correct_topk_without,\n",
    "        },\n",
    "    }\n",
    "    return results\n",
    "\n",
    "results_k1 = evaluate_topk(k=1)\n",
    "results_k5 = evaluate_topk(k=5)\n",
    "\n",
    "def print_results(name, res):\n",
    "    total = res[\"total\"]\n",
    "    if total == 0:\n",
    "        print(f\"{name}: no samples.\")\n",
    "        return\n",
    "    t1 = res[\"top1_correct\"]\n",
    "    tk = res[\"topk_correct\"]\n",
    "    print(\n",
    "        f\"{name}: \"\n",
    "        f\"Top-1 = {t1}/{total} = {t1/total:.4%}, \"\n",
    "        f\"Top-k = {tk}/{total} = {tk/total:.4%}\"\n",
    "    )\n",
    "\n",
    "print(\"=== Top-1 (k=1) ===\")\n",
    "print_results(\"Overall\", results_k1[\"overall\"])\n",
    "print_results(\"With-pair\", results_k1[\"with\"])\n",
    "print_results(\"Without-pair\", results_k1[\"without\"])\n",
    "\n",
    "print(\"\\n=== Top-5 (k=5) ===\")\n",
    "print_results(\"Overall\", results_k5[\"overall\"])\n",
    "print_results(\"With-pair\", results_k5[\"with\"])\n",
    "print_results(\"Without-pair\", results_k5[\"without\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming NUM_CLASSES is defined globally (e.g., NUM_CLASSES = 100)\n",
    "\n",
    "def calculate_metrics_and_print(cm, all_labels, all_preds, best_idx, worst_idx):\n",
    "    \"\"\"Calculates and prints Macro-Averaged and detailed OvR metrics.\"\"\"\n",
    "    \n",
    "    # 1. Get per-class metrics (Precision, Recall, F1-Score)\n",
    "    # labels=np.arange(cm.shape[0]) ensures we calculate for all 100 classes (0-99).\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, labels=np.arange(cm.shape[0]), zero_division=0.0\n",
    "    )\n",
    "    \n",
    "    # 2. Calculate TP, FP, FN, TN (One-vs-Rest approach)\n",
    "    S_total = cm.sum()\n",
    "    TP = cm.diagonal()\n",
    "    FP = cm.sum(axis=0) - TP # Predicted Positive - TP\n",
    "    FN = cm.sum(axis=1) - TP # Actual Positive - TP\n",
    "    TN = S_total - TP - FP - FN # Total - TP - FP - FN\n",
    "\n",
    "    # 3. Aggregate Metrics\n",
    "    macro_precision = precision.mean()\n",
    "    macro_recall = recall.mean()\n",
    "    macro_f1 = f1.mean()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Aggregate Metrics (Macro-Averaged)\")\n",
    "    print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "    print(f\"Macro Recall:    {macro_recall:.4f}\")\n",
    "    print(f\"Macro F1-Score:  {macro_f1:.4f}\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "    # 4. Print Detailed Metrics for Best/Worst Classes\n",
    "    def print_class_metrics(idx, name):\n",
    "        # Only proceed if the class index actually has test samples\n",
    "        if support[idx] == 0:\n",
    "            print(f\"--- Detailed Metrics for {name} Class (Index {idx}) ---\")\n",
    "            print(\"Note: No samples in the test set for this class index.\")\n",
    "            print(\"-\" * 40)\n",
    "            return\n",
    "\n",
    "        accuracy = TP[idx] / support[idx]\n",
    "            \n",
    "        print(f\"--- Detailed Metrics for {name} Class (Index {idx}) ---\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"TP (True Positives):  {TP[idx]}\")\n",
    "        print(f\"TN (True Negatives):  {TN[idx]}\")\n",
    "        print(f\"FP (False Positives): {FP[idx]}\")\n",
    "        print(f\"FN (False Negatives): {FN[idx]}\")\n",
    "        print(f\"Precision: {precision[idx]:.4f}\")\n",
    "        print(f\"Recall:    {recall[idx]:.4f}\")\n",
    "        print(f\"F1-Score:  {f1[idx]:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "    print_class_metrics(best_idx, \"BEST\")\n",
    "    print_class_metrics(worst_idx, \"WORST\")\n",
    "\n",
    "\n",
    "# --- Integration into the original notebook flow ---\n",
    "\n",
    "# 1. Modify the prediction loop (visualize_performance equivalent)\n",
    "#    to return all_labels, all_preds, and cm.\n",
    "\n",
    "# 2. Call the function:\n",
    "#    best_idx, worst_idx = visualize_performance_with_metrics(...)\n",
    "#    calculate_metrics_and_print(cm, all_labels, all_preds, best_idx, worst_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
